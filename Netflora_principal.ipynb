{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbZLKbB8LB9c"
      },
      "source": [
        "# **Netflora na Prática: Guia para detecção de espécies florestais a partir de imagens de drones e inteligência artificial**\n",
        "\n",
        "<p align=\"justify\">Este tutorial é um passo a passo para a detecção de espécies florestais usando a metodologia Netflora, combinando imagens de drones com tecnologias de Inteligência Artificial (IA). Netflora representa um marco tecnológico para o setor florestal, especialmente útil na Amazônia, onde a biodiversidade e a extensão territorial apresentam desafios únicos.\n",
        "\n",
        "## O que você vai aprender?\n",
        "\n",
        "- **Aplicação de IA no Manejo Florestal**:<p align=\"justify\"> Fundamentos sobre como a IA pode ser aplicada para melhorar a identificação e localização de espécies florestais.\n",
        "- **Uso dos Algoritmos Netflora**:<p align=\"justify\"> Instrução detalhada sobre como utilizar os algoritmos Netflora para analisar imagens de drones, visando a identificação precisa de espécies florestais.\n",
        "\n",
        "\n",
        "---\n",
        "---\n",
        "<p align=\"justify\">Aqui vamos tratar do componente “Inventário Florestal com uso de drones”. Drones e inteligência artificial são utilizados para automatizar etapas do inventário florestal na identificação de espécies estratégicas. Mais de 40 mil hectares de áreas de floresta já foram mapeados com o objetivo de coletar informações para compor o dataset do Netflora.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "O Netflora é uma iniciativa desenvolvida pela [Embrapa Acre](https://www.embrapa.br/acre/) com o apoio do [Fundo JBS pela Amazônia](https://fundojbsamazonia.org/).\n",
        "\n",
        "\\\\\n",
        "<div style=\"display: flex;\">\n",
        "\n",
        " <img src=\"https://github.com/NetFlora/NetFlora/blob/main/logo/Netflora.png?raw=true\" width=\"200\" alt=\"Logo Netflora\">\n",
        "\n",
        "  <img src=\"https://github.com/NetFlora/NetFlora/blob/main/logo/Embrapa-Acre.png?raw=true\" width=\"200\" alt=\"Logo JBS\">\n",
        "    \n",
        "   <img src=\"https://github.com/NetFlora/NetFlora/blob/main/logo/Fundo-JBS.png?raw=true\" width=\"200\" alt=\"Logo Fundo JBS\">\n",
        "\n",
        "</div>\n",
        "\n",
        "\\\\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swx_9-vYSwFq"
      },
      "source": [
        "# **Vamos começar!**\n",
        "\n",
        "<p align=\"justify\">Este guia mostra como configurar e executar a detecção de objetos usando o modelo YOLOv7x treinado com a base de dados Netflora no Google Colab.\n",
        "\n",
        "\n",
        "## **Passo 1: Configuração do Ambiente**\n",
        "\n",
        "Primeiramente, crie uma cópia deste notebook no seu Google Colab. **Após criar a cópia, retorne a este guia para continuar o processo de configuração.**\n",
        "\n",
        "Certifique-se de que GPU  foi selecionada como acelerador de hardware para melhorar o desempenho em velocidade da detecção. Isso pode ser veiricado seguindo estas etapas:\n",
        "\n",
        "1. No Google Colab, vá para **`Ambiente de execução`**.\n",
        "2. Selecione **`Alterar tipo de ambiente de execução`**.\n",
        "3. Em **`Acelerador de hardware`**, escolha **`GPU`**.\n",
        "4. Clique em **`Salvar`**.\n",
        "\n",
        "Com a GPU habilitada, você está pronto para prosseguir com as próximas etapas deste guia.\n",
        "\n",
        "#### ⚠️ **Aviso:** O Colab oferece uma GPU Nvidia Tesla T4 de forma gratuíta por aproximadamente 4 horas diárias por usuário. Após esse período, o sistema funcionará normalmente, porém sem acesso à GPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydE1dEJ83B1g"
      },
      "source": [
        "## **Passo 2: Baixe o Repositório Netflora do Github**\n",
        "\n",
        "Execute o código abaixo para clonar o repositório Netflora para o ambiente do Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "vR9IP9cVj9eE"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/NetFlora/Netflora.git\n",
        "#%cd Netflora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEx-0GaE29fQ"
      },
      "source": [
        "## **Passo 3: Autorizar Conexão com Google Drive**\n",
        "\n",
        "Para permitir que este notebook acesse arquivos no seu Google Drive, execute o código abaixo. Isso abrirá uma página de autenticação. Ao abrir a janela, você deverá selecionar uma conta vinculada ao seu Google Drive. Após selecionar, clique em **`Continuar`** para aceitar o compartilhamento. Este processo concede ao Colab permissão para acessar seu Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FeuRZkYe-NW2"
      },
      "outputs": [],
      "source": [
        "from utils.credentials import credentials\n",
        "credentials()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4URVc1ygnKXB"
      },
      "source": [
        "## **Passo 4: Instalação dos Requerimentos**\n",
        "\n",
        "<p align=\"justify\">Instale todos os requerimentos necessários executando o comando abaixo. Os requerimentos são essenciais para o funcionamento adequado do algoritmo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pIBc93lenQ3h"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.19.0 requires keras>=3.5.0, but you have keras 2.10.0 which is incompatible.\n",
            "tensorflow-intel 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 5.29.5 which is incompatible.\n",
            "tensorflow-intel 2.10.0 requires tensorboard<2.11,>=2.10, but you have tensorboard 2.19.0 which is incompatible.\n",
            "\n",
            "[notice] A new release of pip is available: 25.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6jCwiBhSy6q"
      },
      "source": [
        "## **Passo 5: Preparação da Ortofoto**\n",
        "\n",
        "<p align=\"justify\">Para assegurar um processamento eficiente e livre de erros das ortofotos pelo seu computador, é fundamental a segmentação dessas imagens em tiles, o tamanho do tile vai variar de acordo com o algoritmo selecionado. Este tamanho é determindado de acordo com os tamanhos das copas dos indivíduos que estão sendo detectados. Esta abordagem otimiza o processamento devido às demandas computacionais e às especificidades de configuração do Algoritmo.\n",
        "\n",
        "<p align=\"justify\">Não há motivo para preocupação quanto à execução deste processo. Ele pode ser realizado de forma simples e direta em seu Notebook Python. A seguir, apresentamos como segmentar suas imagens em tiles, preparando-as adequadamente para a detecção pelo Algoritmo:\n",
        "\n",
        "\n",
        "Acesse o diretório do seu drive através do menu situado à esquerda. Localize sua ortofoto em `drive/MyDrive/`. Em seguida, clique com o botão direito sobre a ortofoto e selecione **`Copiar caminho`**. Cole este caminho no campo apropriado. Selecione o algoritmo que mais se adequa aos objetivos do seu projeto. Para dar início ao processamento da ortofoto, clique em **`Gerar Tiles`**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "EDGhCVUNpIPG"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0aab6c80e414075bf6fff2c8ee1ef81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Text(value='', description='Ortofoto:', disabled=True, placeholder='Insira o caminho da ortofoto aqui')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce2ee83907564f558c9a5fb022d6556c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dropdown(description='Algoritmo:', disabled=True, options=('Selecione', 'Açaí', 'Palmeiras', 'Castanheira', 'P…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31689d1aafe4428d938194f68e3a4ac1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(description='Gerar Tiles', disabled=True, style=ButtonStyle())"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d026a80bb884544a3a7db6a428ea3bc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<span style=\"color: red;\">Por gentileza, aceite o Termo de Uso!</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<span style=\"color: orange;\">Por favor, preencha os dados e rode essa cécula novamente!</span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a80e38cb00844c0bbbfb5cefe85fde8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Dropdown(description='Translate:', options=(('Português', 'pt'), ('English', 'en'), ('Español',…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<tiles.TileGenerator at 0x20488b7bdc0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tiles import TileGenerator\n",
        "\n",
        "TileGenerator()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hov8fOiBh1vx"
      },
      "source": [
        "## **Passo 6: Execução e detecção**\n",
        "\n",
        "Com o algoritmo e os dados prontos, execute o comando de detecção. A próxima linha de código analizará cada tile individualmente e fará a detecção.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfsVIez7o0m-"
      },
      "outputs": [],
      "source": [
        "!python detect.py --device 0 --weights model_weights.pt --img 1536 --conf 0.25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBYBX86Xnj8p"
      },
      "source": [
        "\n",
        "## **Passo 7: Introdução ao Threshold de Confiança da detecção**\n",
        "\n",
        "<p align=\"justify\">O threshold de confiança, ou limiar de confiança da detecção, é um parâmetro crucial nos modelos automatizados de detecção de objetos. Ele determina o nível mínimo de confiança para que uma detecção seja considerada válida. Em outras palavras, é um filtro que decide se uma previsão feita pelo modelo é suficientemente confiável para ser classificada como a detecção de um objeto.\n",
        "\n",
        "<p align=\"justify\">Lembre-se de que não existe um valor de threshold único que seja ideal para todas as situações, portanto, a personalização baseada em seus requisitos específicos e condições de operação é essencial.\n",
        "\n",
        "<p align=\"justify\">Diante disso, incluimos aqui uma célula de código que possibilitará a você fazer uma análise prévia do comportamento das detecções utilizando diferentes valores de treshold.\n",
        "\n",
        "**Observação:** Esse processo pode ser lento, visto que o algoritmo irá realizar 11 predições para uma amostra do seu banco de dados. Caso voce já saiba qual o valor de theshold irá utilizar pode pular para o **`Passo 8`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fOsSxnBjpIPG"
      },
      "outputs": [],
      "source": [
        "from utils.batch_detection import runBatchDetection\n",
        "\n",
        "runBatchDetection()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxrjil7gHm3I"
      },
      "source": [
        "Visualize o efeito do trheshold em uma amostra de imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zFa-11JIFcd"
      },
      "outputs": [],
      "source": [
        "from utils.thresh_display import ImageDisplayer\n",
        "\n",
        "ImageDisplayer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6rUQrYmc7sd"
      },
      "source": [
        "## **Passo 8: Visualize e exporte seus resultados**\n",
        "\n",
        "Para visualizar os resultados de forma eficaz, procederemos à criação de um arquivo no formato shapefile (.shp). Este arquivo poderá ser facilmente exportado e utilizado em ambientes de Sistemas de Informação Geográfica (SIG), tais como QGIS ou ArcGIS. Essa etapa permite não apenas a visualização detalhada dos dados geoespaciais processados, mas também facilita o manuseio e a análise adicional desses dados em plataformas especializadas de GIS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7nfAM26TdcP"
      },
      "outputs": [],
      "source": [
        "!python results.py --graphics --conf 0.25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI5_IUWSHLZq"
      },
      "source": [
        "Baixe os resultados para seu computador e vizualize a distribuição de frenquência dos indivíduos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gLgbwy0uc9D"
      },
      "outputs": [],
      "source": [
        "from results import downloadResults, showResults\n",
        "\n",
        "downloadResults()\n",
        "showResults()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WSveSf2HcPE"
      },
      "source": [
        "Visualize os resultados da detecção no mapa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cYz3N5BX8n1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from utils.map_utils import createMap\n",
        "\n",
        "createMap()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvnDipjvpIPI"
      },
      "source": [
        "## **Passo 9: Supervisão dos Resultados**\n",
        "\n",
        "\n",
        "Embora as redes neurais artificiais ofereçam capacidades notáveis de predição e análise, a supervisão humana é indispensável para assegurar a integridade e a aplicabilidade de seus resultados. Esta supervisão não só ajuda a evitar erros potencialmente prejudiciais, mas também garante que os sistemas de RNA operem de maneira ética e responsável.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
